{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 3: parameters tuning guide\n",
    "This tutorial shows the different choices of choosing DDN 3.0 hyper-parameters using data driven or probability based methods.\n",
    "\n",
    "It is important to note that the most suitable choice of $\\lambda_1$ and $\\lambda_2$ relies on domain knowledge.\n",
    "We advise user to choose a range of parameters and abserve the resulting networks to determine the parameters.\n",
    "\n",
    "Nonetheless, this tuturial can be useful in providing sometimes tools in choosing $\\lambda_1$ and $\\lambda_2$.\n",
    "\n",
    "We begin with importing some modules. The `parameter_tuning` module contains functions for tuning $\\lambda_1$ and $\\lambda_2$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from ddn3 import tools, simulation, parameter_tuning\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We again generate a synthetic data. The data is the same as used in previous tutorials, except that we only shuffle 3 edges here, and uses less sample sizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "source": [
    "n_node = 40\n",
    "g1_prec, g2_prec = simulation.create_pair_graph(n_node=n_node, corr=0.75, n_shuf=3)\n",
    "\n",
    "g1_cov, _ = simulation.create_cov_prec_mat(g1_prec)\n",
    "g2_cov, _ = simulation.create_cov_prec_mat(g2_prec)\n",
    "\n",
    "dat1 = tools.gen_mv(g1_cov, 40)\n",
    "dat2 = tools.gen_mv(g2_cov, 40)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to initialize the cross validation object.\n",
    "Here we set the number of cross validation to 10, and the ratio of data used for training to be 50%. With this setting, we do repeated two-fold cross validation.\n",
    "Technically, after we estimate the network, for each node, we re-estimate the coefficients using its neighboring nodes only, and calculate the reconstruction error in the validation data.\n",
    "\n",
    "Optionally, users can change the range of $\\lambda_1$ and $\\lambda_2$ values for seaching.\n",
    "\n",
    "Below we will discuss five different choices of choosing $\\lambda_1$ and $\\lambda_2$.\n",
    "They have quite different computational costs. For example, the method that perform grid search cross validation for $\\lambda_1$ and $\\lambda_2$ takes much longer time than methods that rely on two closed form equations.\n",
    "Generally, the former one could be more accurate.\n",
    "\n",
    "Instead of doing grid search cross validation on $\\lambda_1$ and $\\lambda_2$, it is also possible to do cross validation on $\\lambda_1$ or $\\lambda_2$ only, and rely on closed-form statistical equations for the other parameters. \n",
    "\n",
    "For smaller networks, it is better to just use grid search cross validation (option 1).\n",
    "For larger ones, it is advised to use cross validation for $\\lambda_1$, and cross validation or closed form equation for $\\lambda_2$ (option 2 or option 3).\n",
    "The closed form equaiton for $\\lambda_1$ is not robust."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "source": [
    "dp = parameter_tuning.DDNParameterSearch(dat1, dat2, n_cv=10, ratio_validation=0.5)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Option 1: Grid search CV for $\\lambda_1$ and $\\lambda_2$\n",
    "This is the most time consuming option, which searches a grid of $\\lambda_1$ and $\\lambda_2$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "source": [
    "val_err_0, l1_0, l2_0 = dp.fit(\"cv_joint\")\n",
    "print(f\"lambda1={l1_0} lambda2={l2_0}\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cross validation results can be visualized for all combinations of $\\lambda_1$ and $\\lambda_2$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "source": [
    "parameter_tuning.plot_error_2d(val_err_0, cmin=0.67, cmax=0.8)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Option 2: CV for $\\lambda_1$, then CV for $\\lambda_2$\n",
    "We first use cros validation for $\\lambda_1$, then based on the chosen $\\lambda_1$, we do cross validation on $\\lambda_2$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "source": [
    "val_err_1, l1_1, l2_1 = dp.fit(\"cv_sequential\")\n",
    "print(f\"lambda1={l1_1} lambda2={l2_1}\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also plot the cross validation results. First figure is for $\\lambda_1$, and the second for $\\lambda_2$. \n",
    "The red bars means the standard error of the mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "source": [
    "parameter_tuning.plot_error_1d(val_err_1[0], lambda_lst=dp.l1_lst)\n",
    "parameter_tuning.plot_error_1d(val_err_1[1], lambda_lst=dp.l2_lst)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Option 3: CV for $\\lambda_1$, then Bai's method for $\\lambda_2$\n",
    "In this option, we use cross validation to determine $\\lambda_1$, then use the methods in section 4.4 of the DDN 2.0 paper (https://arxiv.org/abs/1203.3532) to determine $\\lambda_2$.\n",
    "We call it Bai's method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "source": [
    "_, l1_cv_bai, l2_cv_bai = dp.fit(\"cv_bai\")\n",
    "print(f\"lambda1={l1_cv_bai} lambda2={l2_cv_bai}\")\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Option 4: MB theorem 3 for $\\lambda_1$, then CV for $\\lambda_2$\n",
    "We use the methods in theorem 3 of the MB algorithm paper (https://arxiv.org/abs/math/0608017) to determine $\\lambda_1$, then use cross validation for $\\lambda_2$.\n",
    "This is not recommended, as that theorem is not always robust."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "source": [
    "_, l1_mb_cv, l2_mb_cv = dp.fit(\"mb_cv\")\n",
    "print(f\"lambda1={l1_mb_cv} lambda2={l2_mb_cv}\")\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Option 5: MB theorem 3 for $\\lambda_1$, then Bai's method for $\\lambda_2$\n",
    "This approach does not use cross validation at all."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "source": [
    "_, l1_mb_bai, l2_mb_bai = dp.fit(\"mb_bai\")\n",
    "print(f\"lambda1={l1_mb_bai} lambda2={l2_mb_bai}\")\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After choosing $\\lambda_1$ and $\\lambda_2$, you can use that in DDN to get the common and differential networks."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
